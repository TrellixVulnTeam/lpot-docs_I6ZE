
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Graph Optimization &#8212; Intel® Low Precision Optimization Tool  documentation</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/blank.css" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Model Conversion" href="model_conversion.html" />
    <link rel="prev" title="Mixed Precision" href="mixed_precision.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    
<a class="navbar-brand" href="../index.html">
<p class="title">Intel® Low Precision Optimization Tool</p>
</a>

    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../README.html">
  Introduction
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="doclist.html">
  Documentation
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../releases_info.html">
  Releases
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../contributions.html">
  Contributing
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../legal_information.html">
  Legal
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../security_policy.html">
  Security
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference external nav-link" href="https://github.com/intel/lpot">
  GitHub
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../system_requirements.html">
   System Requirements
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="transform.html">
   Transform
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="dataset.html">
   Dataset
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="metric.html">
   Metrics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ux.html">
   LPOT UX
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Quantization.html">
   Quantization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="PTQ.html">
   PTQ
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="QAT.html">
   QAT
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="dynamic_quantization.html">
   Dynamic Quantization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="pruning.html">
   Pruning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="benchmark.html">
   Benchmarking
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mixed_precision.html">
   Mixed Precision
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Graph Optimization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="model_conversion.html">
   Model Conversion
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="tensorboard.html">
   TensorBoard
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="adaptor.html">
   Adaptor
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="tuning_strategies.html">
   Tuning Strategies
  </a>
 </li>
</ul>

  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introduction">
   Introduction
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#how-to-use-it">
   How to use it
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#fp32-optimization">
     FP32 Optimization
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#auto-mixed-precision-optimization">
     Auto-mixed Precision Optimization
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#default-auto-mixed-precision">
       Default auto-mixed precision
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#auto-mixed-precision-with-auto-tuning">
       Auto-mixed precision with auto-tuning
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#examples">
   Examples
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     FP32 optimization
    </a>
   </li>
  </ul>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <section id="graph-optimization">
<h1>Graph Optimization<a class="headerlink" href="#graph-optimization" title="Permalink to this headline">¶</a></h1>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h2>
<p>Graph optimization is primarily focused on two scenarios, shown below:</p>
<ol class="simple">
<li><p><strong>FP32 optimization</strong>. This is similar to the TensorFlow optimization tool <a class="reference external" href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/optimize_for_inference.py">optimize_for_inference</a> while LPOT enables more optimizations (such as common subexpression elimination).</p></li>
<li><p><strong>Auto-mixed precision optimization</strong>. LPOT generates the optimal model with auto-mixed precision (<a class="reference external" href="https://cloud.google.com/tpu/docs/bfloat16">bfloat16</a> and FP32) and allows for additional auto-tuning per accuracy requirements.</p></li>
</ol>
</section>
<section id="how-to-use-it">
<h2>How to use it<a class="headerlink" href="#how-to-use-it" title="Permalink to this headline">¶</a></h2>
<p>See the following three examples which demonstrate graph optimization API usage.</p>
<section id="fp32-optimization">
<h3>FP32 Optimization<a class="headerlink" href="#fp32-optimization" title="Permalink to this headline">¶</a></h3>
<p>LPOT runs the graph optimization under FP32 Optimization by default. In other words, the <strong>precisions</strong> field is explicitly set to <strong>fp32</strong>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="kn">from</span> <span class="nn">lpot.experimental</span> <span class="kn">import</span> <span class="n">Graph_Optimization</span>
    <span class="n">graph_optimizer</span> <span class="o">=</span> <span class="n">Graph_Optimization</span><span class="p">()</span>
    <span class="n">graph_optimizer</span><span class="o">.</span><span class="n">precisions</span> <span class="o">=</span> <span class="s1">&#39;fp32&#39;</span> <span class="c1">#Optional, default is &#39;fp32&#39;</span>
    <span class="n">graph_optimizer</span><span class="o">.</span><span class="n">input</span> <span class="o">=</span> <span class="s1">&#39;input&#39;</span>  <span class="c1"># Optional</span>
    <span class="n">graph_optimizer</span><span class="o">.</span><span class="n">output</span> <span class="o">=</span> <span class="s1">&#39;op_to_store&#39;</span>  <span class="c1"># Optional</span>
    <span class="n">graph_optimizer</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="s1">&#39;/path/to/model&#39;</span>
    <span class="n">optimized_model</span> <span class="o">=</span> <span class="n">graph_optimizer</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="auto-mixed-precision-optimization">
<h3>Auto-mixed Precision Optimization<a class="headerlink" href="#auto-mixed-precision-optimization" title="Permalink to this headline">¶</a></h3>
<section id="default-auto-mixed-precision">
<h4>Default auto-mixed precision<a class="headerlink" href="#default-auto-mixed-precision" title="Permalink to this headline">¶</a></h4>
<p>The only difference between this and the default mode (FP32 optimization) is that <strong>bf16</strong> must be added to the <strong>precisions</strong> field.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="kn">from</span> <span class="nn">lpot.experimental</span> <span class="kn">import</span> <span class="n">Graph_Optimization</span>
    <span class="n">graph_optimizer</span> <span class="o">=</span> <span class="n">Graph_Optimization</span><span class="p">()</span>
    <span class="n">graph_optimizer</span><span class="o">.</span><span class="n">precisions</span> <span class="o">=</span> <span class="s1">&#39;bf16, fp32&#39;</span>
    <span class="n">graph_optimizer</span><span class="o">.</span><span class="n">input</span> <span class="o">=</span> <span class="s1">&#39;input&#39;</span>  <span class="c1"># Optional</span>
    <span class="n">graph_optimizer</span><span class="o">.</span><span class="n">output</span> <span class="o">=</span> <span class="s1">&#39;op_to_store&#39;</span>  <span class="c1"># Optional</span>
    <span class="n">graph_optimizer</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="s1">&#39;/path/to/model&#39;</span>
    <span class="n">optimized_model</span> <span class="o">=</span> <span class="n">graph_optimizer</span><span class="p">()</span>
</pre></div>
</div>
<p>Note the <strong>fp32</strong> is optional when the <strong>bf16</strong> is set to precisions field. The below example has the identical action under the hardware platform supports bf16, e.g, the CPX platform.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="kn">from</span> <span class="nn">lpot.experimental</span> <span class="kn">import</span> <span class="n">Graph_Optimization</span>
    <span class="n">graph_optimizer</span> <span class="o">=</span> <span class="n">Graph_Optimization</span><span class="p">()</span>
    <span class="n">graph_optimizer</span><span class="o">.</span><span class="n">precisions</span> <span class="o">=</span> <span class="s1">&#39;bf16&#39;</span>
    <span class="n">graph_optimizer</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="s1">&#39;/path/to/model&#39;</span>
    <span class="n">optimized_model</span> <span class="o">=</span> <span class="n">graph_optimizer</span><span class="p">()</span>
</pre></div>
</div>
<p>For those platforms without bf16 enabling, like CLX. LPOT also could leverage the graph optimization feature to generate the model under bf16 precision.The usage is just adding the <code class="docutils literal notranslate"><span class="pre">FORCE_BF16=1</span></code> before the cmd.
e.g, <code class="docutils literal notranslate"><span class="pre">FORCE_BF16=1</span> <span class="pre">/path/to/executable_lpot_wrapper</span></code>. If we don’t add such prefix <code class="docutils literal notranslate"><span class="pre">FORCE_BF16=1</span></code>, the LPOT would exit consequently.</p>
</section>
<section id="auto-mixed-precision-with-auto-tuning">
<h4>Auto-mixed precision with auto-tuning<a class="headerlink" href="#auto-mixed-precision-with-auto-tuning" title="Permalink to this headline">¶</a></h4>
<p>LPOT also supports tuning the model in graph optimization mode. The end user must replace the quantization field with graph_optimization parts such as shown below. The <strong>precisions</strong> field only supports <strong>bf16</strong> and <strong>fp32</strong>.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">graph_optimization</span><span class="p">:</span>
  <span class="nt">precisions</span><span class="p">:</span> <span class="p p-Indicator">[</span><span class="s">&#39;bf16&#39;</span><span class="p p-Indicator">,</span> <span class="s">&#39;fp32&#39;</span><span class="p p-Indicator">]</span>
</pre></div>
</div>
<p>Note that if we remove the evaluation field from the yaml file, the graph optimization will only convert the model depending on the precisions setting.</p>
<p>When the graph_optimization field is set and the evaluation field exists in the yaml file, LPOT executes the similar process like quantization. It means the LPOT converts op into bf16 as much as possible and checks the metric later. If the metric meets the criterion, LPOT exits or it fallbacks one op to fp32 and re-runs the above process until it meets the exit policy setting.</p>
<p>Below is an example of using yaml to trigger graph optimization.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="kn">from</span> <span class="nn">lpot.experimental</span> <span class="kn">import</span> <span class="n">Graph_Optimization</span>
    <span class="n">graph_optimizer</span> <span class="o">=</span> <span class="n">Graph_Optimization</span><span class="p">(</span><span class="s1">&#39;/path/to/config.yaml&#39;</span><span class="p">)</span>
    <span class="n">graph_optimizer</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="s1">&#39;/path/to/model&#39;</span>
    <span class="n">optimized_model</span> <span class="o">=</span> <span class="n">graph_optimizer</span><span class="p">()</span>
</pre></div>
</div>
</section>
</section>
</section>
<section id="examples">
<h2>Examples<a class="headerlink" href="#examples" title="Permalink to this headline">¶</a></h2>
<section id="id1">
<h3>FP32 optimization<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<p>The below example demonstrate how to speed up the Resnet50 FP32 throughput performance via Graph Optimization.</p>
<ol class="simple">
<li><p>Download the pre-trained ResNet-50 model with below command.</p></li>
</ol>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>  wget https://storage.googleapis.com/intel-optimized-tensorflow/models/v1_6/resnet50_fp32_pretrained_model.pb
</pre></div>
</div>
<ol class="simple">
<li><p>Measure the performance on original FP32 model.</p></li>
</ol>
<p>First of all, we create the <strong>resnet50_measurement.yaml</strong> with below settings for leveraging LPOT Benchmark API.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span>  <span class="nt">model</span><span class="p">:</span>
    <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">resnet50_v1</span>
    <span class="nt">framework</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">tensorflow</span>

  <span class="nt">evaluation</span><span class="p">:</span>
    <span class="nt">performance</span><span class="p">:</span>
      <span class="nt">configs</span><span class="p">:</span>
        <span class="nt">cores_per_instance</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">28</span>
        <span class="nt">num_of_instance</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>
      <span class="nt">dataloader</span><span class="p">:</span>
        <span class="nt">batch_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">100</span>
        <span class="nt">dataset</span><span class="p">:</span>
          <span class="nt">dummy</span><span class="p">:</span>
            <span class="nt">shape</span><span class="p">:</span> <span class="p p-Indicator">[</span><span class="nv">1000</span><span class="p p-Indicator">,</span> <span class="nv">224</span><span class="p p-Indicator">,</span> <span class="nv">224</span><span class="p p-Indicator">,</span> <span class="nv">3</span><span class="p p-Indicator">]</span>
</pre></div>
</div>
<p>Then, we can leverage the Benchmark API to measure the performance.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">lpot.experimental</span> <span class="kn">import</span> <span class="n">Benchmark</span>
<span class="n">evaluator</span> <span class="o">=</span> <span class="n">Benchmark</span><span class="p">(</span><span class="s1">&#39;/path/to/resnet50_measurement.yaml&#39;</span><span class="p">)</span>
<span class="n">evaluator</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="s1">&#39;/path/to/resnet50_fp32_pretrained_model.pb&#39;</span>
<span class="n">evaluator</span><span class="p">(</span><span class="s1">&#39;performance&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>We got below performance result under Intel Xeon Scalable processor Cascade Lake 8280.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>performance mode benchmark result:
<span class="m">2021</span>-05-28 <span class="m">15</span>:16:11 <span class="o">[</span>INFO<span class="o">]</span> Batch <span class="nv">size</span> <span class="o">=</span> <span class="m">100</span>
<span class="m">2021</span>-05-28 <span class="m">15</span>:16:11 <span class="o">[</span>INFO<span class="o">]</span> Latency: <span class="m">7</span>.165 ms
<span class="m">2021</span>-05-28 <span class="m">15</span>:16:11 <span class="o">[</span>INFO<span class="o">]</span> Throughput: <span class="m">139</span>.567 images/sec
</pre></div>
</div>
<ol class="simple">
<li><p>Re-Measure the performance on optimized FP32 model.</p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">lpot.experimental</span> <span class="kn">import</span> <span class="n">Graph_Optimization</span>

<span class="n">graph_optimizer</span> <span class="o">=</span> <span class="n">Graph_Optimization</span><span class="p">()</span>
<span class="n">graph_optimizer</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="s1">&#39;/path/to/resnet50_fp32_pretrained_model.pb&#39;</span>
<span class="n">output_graph</span> <span class="o">=</span> <span class="n">graph_optimizer</span><span class="p">()</span>
<span class="n">output_graph</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;/path/to/fp32_optimized_model&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>Then, We measure the optimized performance via LPOT Benchmark API again.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">lpot.experimental</span> <span class="kn">import</span> <span class="n">Benchmark</span>
<span class="n">evaluator</span> <span class="o">=</span> <span class="n">Benchmark</span><span class="p">(</span><span class="s1">&#39;/path/to/resnet50_measurement.yaml&#39;</span><span class="p">)</span>
<span class="n">evaluator</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="s1">&#39;/path/to/fp32_optimized_model&#39;</span>
<span class="n">evaluator</span><span class="p">(</span><span class="s1">&#39;performance&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>Now, the throughput has been improved ~2.3x (325.99 vs 139.56) compared with the initial data.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>performance mode benchmark result:
<span class="m">2021</span>-05-28 <span class="m">15</span>:16:41 <span class="o">[</span>INFO<span class="o">]</span> Batch <span class="nv">size</span> <span class="o">=</span> <span class="m">100</span>
<span class="m">2021</span>-05-28 <span class="m">15</span>:16:41 <span class="o">[</span>INFO<span class="o">]</span> Latency: <span class="m">3</span>.068 ms
<span class="m">2021</span>-05-28 <span class="m">15</span>:16:41 <span class="o">[</span>INFO<span class="o">]</span> Throughput: <span class="m">325</span>.992 images/sec
</pre></div>
</div>
</section>
</section>
</section>


              </div>
              
              
              <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="mixed_precision.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Mixed Precision</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="model_conversion.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Model Conversion</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
              
          </main>
          

      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>
<footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2021, Intel® Low Precision Optimization Tool.<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.3.0.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>