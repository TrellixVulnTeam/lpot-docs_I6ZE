
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Model &#8212; Intel® Low Precision Optimization Tool  documentation</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/blank.css" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    
<a class="navbar-brand" href="../index.html">
<p class="title">Intel® Low Precision Optimization Tool</p>
</a>

    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../README.html">
  Introduction
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="doclist.html">
  Documentation
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../releases_info.html">
  Releases
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../contributions.html">
  Contributing
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../legal_information.html">
  Legal
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../security_policy.html">
  Security
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference external nav-link" href="https://github.com/intel/lpot">
  GitHub
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    
  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#framework-model-support-list">
   Framework model support list
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tensorflow">
     TensorFlow
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mxnet">
     MXNet
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#pytorch">
     PyTorch
    </a>
   </li>
  </ul>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <section id="model">
<h1>Model<a class="headerlink" href="#model" title="Permalink to this headline">¶</a></h1>
<p>The LPOT Model feature is used to encapsulate the behavior of model building and saving. By simply providing information such as different model formats and framework_specific_info, LPOT performs optimizations and quantization on this model object and returns an LPOT Model object for further model persisting or benchmarking. An LPOT Model helps users to maintain necessary model information which is needed during optimization and quantization such as the input/output names, workspace path, and other model format knowledge. This helps unify the features gap brought by different model formats and frameworks.</p>
<p>Users can create, use, and save models in the following manner:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">lpot</span> <span class="kn">import</span> <span class="n">Quantization</span><span class="p">,</span> <span class="n">common</span>
<span class="n">quantizer</span> <span class="o">=</span> <span class="n">Quantization</span><span class="p">(</span><span class="s1">&#39;./conf.yaml&#39;</span><span class="p">)</span>
<span class="n">quantizer</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">common</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="s1">&#39;/path/to/model&#39;</span><span class="p">)</span>
<span class="n">q_model</span> <span class="o">=</span> <span class="n">quantizer</span><span class="p">()</span>
<span class="n">q_model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>
</pre></div>
</div>
<section id="framework-model-support-list">
<h2>Framework model support list<a class="headerlink" href="#framework-model-support-list" title="Permalink to this headline">¶</a></h2>
<section id="tensorflow">
<h3>TensorFlow<a class="headerlink" href="#tensorflow" title="Permalink to this headline">¶</a></h3>
<table border="1" class="docutils">
<thead>
<tr>
<th>Model format</th>
<th>Parameters</th>
<th>Comments</th>
<th>Usage</th>
</tr>
</thead>
<tbody>
<tr>
<td>frozen pb</td>
<td><strong>model</strong>(str): path to frozen pb <br> <strong>framework_specific_info</strong>(dict): information about model and framework, such as input_tensor_names, input_tensor_names, workspace_path and name <br> <strong>kwargs</strong>(dict): other required parameters</td>
<td><strong>Examples</strong>: <br> <a href="../examples/tensorflow/image_recognition">../examples/tensorflow/image_recognition</a> <br> <a href="../examples/tensorflow/oob_models">../examples/tensorflow/oob_models</a> <br> <strong>Save format</strong>: <br> frozen pb</td>
<td>from lpot.experimental import Quantization, common <br> quantizer = Quantization(args.config) <br> quantizer.model = common.Model(model) <br> q_model = quantizer() <br> <strong>model is the path of model, like ./path/to/frozen.pb</strong></td>
</tr>
<tr>
<td>Graph object</td>
<td><strong>model</strong>(tf.compat.v1.Graph): tf.compat.v1.Graph object  <br> <strong>framework_specific_info</strong>(dict): information about model and framework, such as input_tensor_names, input_tensor_names, workspace_path and name <br> <strong>kwargs</strong>(dict): other required parameters</td>
<td><strong>Examples</strong>: <br> <a href="../examples/tensorflow/style_transfer">../examples/tensorflow/style_transfer</a> <br> <a href="../examples/tensorflow/recommendation/wide_deep_large_ds">../examples/tensorflow/recommendation/wide_deep_large_ds</a> <br> <strong>Save format</strong>: <br> frozen pb</td>
<td>from lpot.experimental import Quantization, common <br> quantizer = Quantization(args.config) <br> quantizer.model = common.Model(model) <br> q_model = quantizer() <br> <strong>model is the object of tf.compat.v1.Graph</strong></td>
</tr>
<tr>
<td>Graph object</td>
<td><strong>model</strong>(tf.compat.v1.GraphDef) tf.compat.v1.GraphDef object <br> <strong>framework_specific_info</strong>(dict): information about model and framework, such as input_tensor_names, input_tensor_names, workspace_path and name <br> <strong>kwargs</strong>(dict): other required parameters</td>
<td><strong>Save format</strong>: <br> frozen pb</td>
<td>from lpot.experimental import Quantization, common <br> quantizer = Quantization(args.config) <br> quantizer.model = common.Model(model) <br> q_model = quantizer() <br> <strong>model is the object of tf.compat.v1.GraphDef</strong></td>
</tr>
<tr>
<td>tf1.x checkpoint</td>
<td><strong>model</strong>(str): path to checkpoint <br> <strong>framework_specific_info</strong>(dict): information about model and framework, such as input_tensor_names, input_tensor_names, workspace_path and name <br> <strong>kwargs</strong>(dict): other required parameters</td>
<td><strong>Examples</strong>: <br> <a href="../examples/helloworld/tf_example4">../examples/helloworld/tf_example4</a> <br> <a href="../examples/tensorflow/object_detection">../examples/tensorflow/object_detection</a>  <br> <strong>Save format</strong>: <br> frozen pb</td>
<td>from lpot.experimental import Quantization, common <br> quantizer = Quantization(args.config) <br> quantizer.model = common.Model(model) <br> q_model = quantizer() <br> <strong>model is the path of model, like ./path/to/ckpt/</strong></td>
</tr>
<tr>
<td>keras.Model object</td>
<td><strong>model</strong>(tf.keras.Model): tf.keras.Model object <br> <strong>framework_specific_info</strong>(dict): information about model and framework, such as input_tensor_names, input_tensor_names, workspace_path and name <br> <strong>kwargs</strong>(dict): other required parameters</td>
<td><strong>Save format</strong>: <br> keras saved model</td>
<td>from lpot.experimental import Quantization, common <br> quantizer = Quantization(args.config) <br> quantizer.model = common.Model(model) <br> q_model = quantizer() <br> <strong>model is the object of tf.keras.Model</strong></td>
</tr>
<tr>
<td>keras saved model</td>
<td><strong>model</strong>(str): path to keras saved model <br> <strong>framework_specific_info</strong>(dict): information about model and framework, such as input_tensor_names, input_tensor_names, workspace_path and name <br> <strong>kwargs</strong>(dict): other required parameters</td>
<td><strong>Examples</strong>: <br> <a href="../examples/helloworld/tf_example2">../examples/helloworld/tf_example2</a> <br> <strong>Save format</strong>: <br> keras saved model</td>
<td>from lpot.experimental import Quantization, common <br> quantizer = Quantization(args.config) <br> quantizer.model = common.Model(model) <br> q_model = quantizer() <br> <strong>model is the path of model, like ./path/to/saved_model/</strong></td>
</tr>
<tr>
<td>tf2.x saved model</td>
<td><strong>model</strong>(str): path to saved model <br> <strong>framework_specific_info</strong>(dict): information about model and framework, such as input_tensor_names, input_tensor_names, workspace_path and name <br> <strong>kwargs</strong>(dict): other required parameters</td>
<td><strong>Save format</strong>: <br> saved model</td>
<td>from lpot.experimental import Quantization, common <br> quantizer = Quantization(args.config) <br> quantizer.model = common.Model(model) <br> q_model = quantizer() <br> <strong>model is the path of model, like ./path/to/saved_model/</strong></td>
</tr>
<tr>
<td>tf2.x h5 format model</td>
<td></td>
<td>TBD</td>
<td></td>
</tr>
<tr>
<td>slim checkpoint</td>
<td><strong>model</strong>(str): path to slim checkpoint <br> <strong>framework_specific_info</strong>(dict): information about model and framework, such as input_tensor_names, input_tensor_names, workspace_path and name <br> <strong>kwargs</strong>(dict): other required parameters</td>
<td><strong>Examples</strong>: <br> <a href="../examples/helloworld/tf_example3">../examples/helloworld/tf_example3</a> <br> <strong>Save format</strong>: <br> frozen pb</td>
<td>from lpot.experimental import Quantization, common <br> quantizer = Quantization(args.config) <br> quantizer.model = common.Model(model) <br> q_model = quantizer() <br> <strong>model is thepath of model, like ./path/to/model.ckpt</strong></td>
</tr>
<tr>
<td>tf1.x saved model</td>
<td><strong>model</strong>(str): path to saved model, <strong>framework_specific_info</strong>(dict): information about model and framework, such as input_tensor_names, input_tensor_names, workspace_path and name <br> <strong>kwargs</strong>(dict): other required parameters</td>
<td><strong>Save format</strong>: <br> saved model</td>
<td>from lpot.experimental import Quantization, common <br> quantizer = Quantization(args.config) <br> quantizer.model = common.Model(model) <br> q_model = quantizer() <br> <strong>model is the path of model, like ./path/to/saved_model/</strong></td>
</tr>
<tr>
<td>tf2.x checkpoint</td>
<td></td>
<td>Not support yes. As tf2.x checkpoint only has weight and does not contain any description of the computation, please use different tf2.x model for quantization</td>
<td></td>
</tr>
</tbody>
</table><p>The following methods can be used in the TensorFlow model:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">graph_def</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">graph_def</span>
<span class="n">input_tensor_names</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">input_tensor_names</span>
<span class="n">model</span><span class="o">.</span><span class="n">input_tensor_names</span> <span class="o">=</span> <span class="n">input_tensor_names</span>
<span class="n">output_tensor_names</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">output_tensor_names</span>
<span class="n">model</span><span class="o">.</span><span class="n">output_tensor_names</span> <span class="o">=</span> <span class="n">output_tensor_names</span>
<span class="n">input_node_names</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">input_node_names</span>
<span class="n">output_node_names</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">output_node_names</span>
<span class="n">input_tensor</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">input_tensor</span>
<span class="n">output_tensor</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">output_tensor</span>
</pre></div>
</div>
</section>
<section id="mxnet">
<h3>MXNet<a class="headerlink" href="#mxnet" title="Permalink to this headline">¶</a></h3>
<table border="1" class="docutils">
<thead>
<tr>
<th>Model format</th>
<th>Parameters</th>
<th>Comments</th>
<th>Usage</th>
</tr>
</thead>
<tbody>
<tr>
<td>mxnet.gluon.HybridBlock</td>
<td><strong>model</strong>(mxnet.gluon.HybridBlock): mxnet.gluon.HybridBlock object <br> <strong>framework_specific_info</strong>(dict): information about model and framework <br> <strong>kwargs</strong>(dict): other required parameters</td>
<td><strong>Save format</strong>: <br> save_path.json</td>
<td>from lpot.experimental import Quantization, common <br> quantizer = Quantization(args.config) <br> quantizer.model = common.Model(model) <br> q_model = quantizer() <br> <strong>model is mxnet.gluon.HybridBlock object</strong></td>
</tr>
<tr>
<td>mxnet.symbol.Symbol</td>
<td><strong>model</strong>(tuple): tuple of symbol, arg_params, aux_params <br> <strong>framework_specific_info</strong>(dict): information about model and framework <br> <strong>kwargs</strong>(dict): other required parameters</td>
<td><strong>Save format</strong>: <br> save_path-symbol.json and save_path-0000.params</td>
<td>from lpot.experimental import Quantization, common <br> quantizer = Quantization(args.config) <br> quantizer.model = common.Model(model) <br> q_model = quantizer() <br> <strong>model is the tuple of symbol, arg_params, aux_params</strong></td>
</tr>
</tbody>
</table><ul class="simple">
<li><p>Get symbol, arg_params, aux_params from symbol and param files.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mxnet</span> <span class="k">as</span> <span class="nn">mx</span>
<span class="kn">from</span> <span class="nn">mxnet</span> <span class="kn">import</span> <span class="n">nd</span>

<span class="n">symbol</span> <span class="o">=</span> <span class="n">mx</span><span class="o">.</span><span class="n">sym</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">symbol_file_path</span><span class="p">)</span>
<span class="n">save_dict</span> <span class="o">=</span> <span class="n">nd</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">param_file_path</span><span class="p">)</span>
<span class="n">arg_params</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">aux_params</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">save_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">tp</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="n">k</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;:&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">tp</span> <span class="o">==</span> <span class="s1">&#39;arg&#39;</span><span class="p">:</span>
        <span class="n">arg_params</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>
    <span class="k">if</span> <span class="n">tp</span> <span class="o">==</span> <span class="s1">&#39;aux&#39;</span><span class="p">:</span>
        <span class="n">aux_params</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>
</pre></div>
</div>
</section>
<section id="pytorch">
<h3>PyTorch<a class="headerlink" href="#pytorch" title="Permalink to this headline">¶</a></h3>
<table border="1" class="docutils">
<thead>
<tr>
<th>Model format</th>
<th>Parameters</th>
<th>Comments</th>
<th>Usage</th>
</tr>
</thead>
<tbody>
<tr>
<td>torch.nn.model</td>
<td><strong>model</strong>(torch.nn.model): torch.nn.model object <br> <strong>framework_specific_info</strong>(dict): information about model and framework <br> <strong>kwargs</strong>(dict): other required parameters</td>
<td><strong>Save format</strong>: <br> Without Intel PyTorch Extension(IPEX): /save_path/best_configure.yaml and /save_path/best_model_weights.pt <br> With IPEX: /save_path/best_configure.json</td>
<td>from lpot.experimental import Quantization, common <br> quantizer = Quantization(args.config) <br> quantizer.model = common.Model(model) <br> q_model = quantizer() <br> <strong>model is torch.nn.model object</strong></td>
</tr>
</tbody>
</table><ul class="simple">
<li><p>Loading model:</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Without IPEX</span>
<span class="kn">from</span> <span class="nn">lpot.utils.pytorch</span> <span class="kn">import</span> <span class="n">load</span>
<span class="n">quantized_model</span> <span class="o">=</span> <span class="n">load</span><span class="p">(</span>
    <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(</span><span class="n">Path</span><span class="p">)),</span> <span class="n">model</span><span class="p">)</span> <span class="c1"># model is a fp32 model</span>

<span class="c1"># With IPEX</span>
<span class="kn">import</span> <span class="nn">intel_pytorch_extension</span> <span class="k">as</span> <span class="nn">ipex</span>
<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">ipex</span><span class="o">.</span><span class="n">DEVICE</span><span class="p">)</span> <span class="c1"># model is a fp32 model</span>
<span class="k">try</span><span class="p">:</span>
    <span class="n">new_model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">script</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="k">except</span><span class="p">:</span>
    <span class="n">new_model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">ipex</span><span class="o">.</span><span class="n">DEVICE</span><span class="p">))</span>
<span class="n">ipex_config_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">tuned_checkpoint</span><span class="p">),</span>
                                <span class="s2">&quot;best_configure.json&quot;</span><span class="p">)</span>
<span class="n">conf</span> <span class="o">=</span> <span class="n">ipex</span><span class="o">.</span><span class="n">AmpConf</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">int8</span><span class="p">,</span> <span class="n">configure_file</span><span class="o">=</span><span class="n">ipex_config_path</span><span class="p">)</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="k">with</span> <span class="n">ipex</span><span class="o">.</span><span class="n">AutoMixPrecision</span><span class="p">(</span><span class="n">conf</span><span class="p">,</span> <span class="n">running_mode</span><span class="o">=</span><span class="s1">&#39;inference&#39;</span><span class="p">):</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">new_model</span><span class="p">(</span><span class="nb">input</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">ipex</span><span class="o">.</span><span class="n">DEVICE</span><span class="p">))</span>
</pre></div>
</div>
</section>
</section>
</section>


              </div>
              
              
              <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
              
          </main>
          

      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>
<footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2021, Intel® Low Precision Optimization Tool.<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.3.0.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>