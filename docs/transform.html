
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Transform &#8212; Intel® Low Precision Optimization Tool  documentation</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/blank.css" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Dataset" href="dataset.html" />
    <link rel="prev" title="System Requirements" href="../system_requirements.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    
<a class="navbar-brand" href="../index.html">
<p class="title">Intel® Low Precision Optimization Tool</p>
</a>

    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../README.html">
  Introduction
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="doclist.html">
  Documentation
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../releases_info.html">
  Releases
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../contributions.html">
  Contributing
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../legal_information.html">
  Legal
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../security_policy.html">
  Security
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference external nav-link" href="https://github.com/intel/lpot">
  GitHub
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    
  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#transform-support-list">
   Transform support list
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tensorflow">
     TensorFlow
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#pytorch">
     Pytorch
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mxnet">
     MXNet
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#onnxrt">
     ONNXRT
    </a>
   </li>
  </ul>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <section id="transform">
<h1>Transform<a class="headerlink" href="#transform" title="Permalink to this headline">¶</a></h1>
<p>LPOT supports built-in preprocessing methods on different framework backends. Refer to <a class="reference external" href="https://github.com/intel/lpot/tree/master/examples/helloworld/tf_example1">this HelloWorld example</a> on how to configure a transform in a dataloader.</p>
<section id="transform-support-list">
<h2>Transform support list<a class="headerlink" href="#transform-support-list" title="Permalink to this headline">¶</a></h2>
<section id="tensorflow">
<h3>TensorFlow<a class="headerlink" href="#tensorflow" title="Permalink to this headline">¶</a></h3>
<table border="1" class="docutils">
<thead>
<tr>
<th align="left">Transform</th>
<th align="left">Parameters</th>
<th align="left">Comments</th>
<th align="left">Usage(In yaml file)</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">Resize(size, interpolation)</td>
<td align="left"><strong>size</strong> (list or int): Size of the result <br> <strong>interpolation</strong> (str, default='bilinear'):Desired interpolation type, support 'bilinear', 'nearest', 'bicubic'</td>
<td align="left">Resize the input image to the given size</td>
<td align="left">Resize: <br> &ensp;&ensp; size: 256 <br> &ensp;&ensp;  interpolation: bilinear</td>
</tr>
<tr>
<td align="left">CenterCrop(size)</td>
<td align="left"><strong>size</strong> (list or int): Size of the result</td>
<td align="left">Crops the given image at the center to the given size</td>
<td align="left">CenterCrop: <br> &ensp;&ensp; size: [10, 10] # or size: 10</td>
</tr>
<tr>
<td align="left">RandomResizedCrop(size, scale, ratio, interpolation)</td>
<td align="left"><strong>size</strong> (list or int): Size of the result <br> <strong>scale</strong> (tuple or list, default=(0.08, 1.0)):range of size of the origin size cropped <br> <strong>ratio</strong> (tuple or list, default=(3. / 4., 4. / 3.)): range of aspect ratio of the origin aspect ratio cropped <br> <strong>interpolation</strong> (str, default='bilinear'):Desired interpolation type, support 'bilinear', 'nearest'</td>
<td align="left">Crop the given image to random size and aspect ratio</td>
<td align="left">RandomResizedCrop: <br> &ensp;&ensp; size: [10, 10] # or size: 10 <br> &ensp;&ensp; scale: [0.08, 1.0] <br> &ensp;&ensp; ratio: [3. / 4., 4. / 3.] <br> &ensp;&ensp; interpolation: bilinear</td>
</tr>
<tr>
<td align="left">Normalize(mean, std)</td>
<td align="left"><strong>mean</strong> (list, default=[0.0]):means for each channel, if len(mean)=1, mean will be broadcasted to each channel, otherwise its length should be same with the length of image shape <br> <strong>std</strong> (list, default=[1.0]):stds for each channel, if len(std)=1, std will be broadcasted to each channel, otherwise its length should be same with the length of image shape</td>
<td align="left">Normalize a image with mean and standard deviation</td>
<td align="left">Normalize: <br> &ensp;&ensp; mean: [0.0, 0.0, 0.0] <br> &ensp;&ensp; std: [1.0, 1.0, 1.0]</td>
</tr>
<tr>
<td align="left">RandomCrop(size)</td>
<td align="left"><strong>size</strong> (list or int): Size of the result</td>
<td align="left">Crop the image at a random location to the given size</td>
<td align="left">RandomCrop: <br> &ensp;&ensp; size: [10, 10] # size: 10</td>
</tr>
<tr>
<td align="left">Compose(transform_list)</td>
<td align="left"><strong>transform_list</strong> (list of Transform objects):  list of transforms to compose</td>
<td align="left">Composes several transforms together</td>
<td align="left">If user uses yaml file to configure transforms, LPOT will automatic call Compose to group other transforms. <br> <strong>In user code:</strong> <br> from lpot.experimental.data  import TRANSFORMS <br> preprocess = TRANSFORMS(framework, 'preprocess') <br> resize = preprocess["Resize"] (*<em>args) <br> normalize = preprocess["Normalize"] (*</em>args) <br> compose = preprocess["Compose"] ([resize, normalize]) <br> sample = compose(sample) <br> # sample: image, label</td>
</tr>
<tr>
<td align="left">CropResize(x, y, width, height, size, interpolation)</td>
<td align="left"><strong>x</strong> (int):Left boundary of the cropping area <br> <strong>y</strong> (int):Top boundary of the cropping area <br> <strong>width</strong> (int):Width of the cropping area <br> <strong>height</strong> (int):Height of the cropping area <br> <strong>size</strong> (list or int): resize to new size after cropping <br> <strong>interpolation</strong> (str, default='bilinear'):Desired interpolation type, support 'bilinear', 'nearest' and 'bicubic'</td>
<td align="left">Crop the input image with given location and resize it</td>
<td align="left">CropResize: <br> &ensp;&ensp; x: 0 <br> &ensp;&ensp; y: 5 <br> &ensp;&ensp; width: 224 <br> &ensp;&ensp; height: 224 <br> &ensp;&ensp; size: [100, 100] # or size: 100 <br> &ensp;&ensp; interpolation: bilinear</td>
</tr>
<tr>
<td align="left">RandomHorizontalFlip()</td>
<td align="left">None</td>
<td align="left">Horizontally flip the given image randomly</td>
<td align="left">RandomHorizontalFlip: {}</td>
</tr>
<tr>
<td align="left">RandomVerticalFlip()</td>
<td align="left">None</td>
<td align="left">Vertically flip the given image randomly</td>
<td align="left">RandomVerticalFlip: {}</td>
</tr>
<tr>
<td align="left">DecodeImage()</td>
<td align="left">None</td>
<td align="left">Decode a JPEG-encoded image to a uint8 tensor</td>
<td align="left">DecodeImage: {}</td>
</tr>
<tr>
<td align="left">EncodeJped()</td>
<td align="left">None</td>
<td align="left">Encode image to a  Tensor of type string</td>
<td align="left">EncodeJped: {}</td>
</tr>
<tr>
<td align="left">Transpose(perm)</td>
<td align="left"><strong>perm</strong> (list): A permutation of the dimensions of input image</td>
<td align="left">Transpose image according perm</td>
<td align="left">Transpose: <br> &ensp;&ensp; perm: [1, 2, 0]</td>
</tr>
<tr>
<td align="left">ResizeWithRatio(min_dim, max_dim, padding)</td>
<td align="left"><strong>min_dim</strong> (int, default=800): Resizes the image such that its smaller dimension == min_dim <br> <strong>max_dim</strong> (int, default=1365): Ensures that the image longest side does not exceed this value <br> <strong>padding</strong> (bool, default=False): If true, pads image with zeros so its size is max_dim x max_dim</td>
<td align="left">Resize image with aspect ratio and pad it to max shape(optional). If the image is padded, the label will be processed at the same time. The input image should be np.array or tf.Tensor.</td>
<td align="left">ResizeWithRatio: <br> &ensp;&ensp; min_dim: 800 <br> &ensp;&ensp; max_dim: 1365 <br> &ensp;&ensp; padding: True</td>
</tr>
<tr>
<td align="left">CropToBoundingBox(offset_height, offset_width, target_height, target_width)</td>
<td align="left"><strong>offset_height</strong> (int): Vertical coordinate of the top-left corner of the result in the input <br> <strong>offset_width</strong> (int): Horizontal coordinate of the top-left corner of the result in the input <br> <strong>target_height</strong> (int): Height of the result <br> <strong>target_width</strong> (int): Width of the result</td>
<td align="left">Crops an image to a specified bounding box</td>
<td align="left">CropToBoundingBox: <br> &ensp;&ensp; offset_height: 10 <br> &ensp;&ensp; offset_width: 10 <br> &ensp;&ensp; target_height: 224 <br> &ensp;&ensp; 224</td>
</tr>
<tr>
<td align="left">Cast(dtype)</td>
<td align="left"><strong>dtype</strong> (str, default='float32'): A dtype to convert image to</td>
<td align="left">Convert image to given dtype</td>
<td align="left">Cast: <br> &ensp;&ensp; dtype: float32</td>
</tr>
<tr>
<td align="left">ToArray()</td>
<td align="left">None</td>
<td align="left">Convert PIL Image to numpy array</td>
<td align="left">ToArray: {}</td>
</tr>
<tr>
<td align="left">Rescale()</td>
<td align="left">None</td>
<td align="left">Scale the values of image to [0,1]</td>
<td align="left">Rescale: {}</td>
</tr>
<tr>
<td align="left">AlignImageChannel(dim)</td>
<td align="left"><strong>dim</strong> (int): The channel number of result image</td>
<td align="left">Align image channel, now just support [H,W]-&gt;[H,W,dim], [H,W,4]-&gt;[H,W,3] and [H,W,3]-&gt;[H,W]</td>
<td align="left">AlignImageChannel: <br> &ensp;&ensp; dim: 3</td>
</tr>
<tr>
<td align="left">ParseDecodeImagenet()</td>
<td align="left">None</td>
<td align="left">Parse features in Example proto</td>
<td align="left">ParseDecodeImagenet: {}</td>
</tr>
<tr>
<td align="left">ResizeCropImagenet(height, width, random_crop, resize_side, random_flip_left_right, mean_value, scale)</td>
<td align="left"><strong>height</strong> (int): Height of the result <br> <strong>width</strong> (int): Width of the result <br> <strong>random_crop</strong> (bool, default=False): whether to random crop <br> <strong>resize_side</strong> (int, default=256):desired shape after resize operation <br> <strong>random_flip_left_right</strong> (bool, default=False): whether to random flip left and right <br> <strong>mean_value</strong> (list, default=[0.0,0.0,0.0]):means for each channel <br> <strong>scale</strong> (float, default=1.0):std value</td>
<td align="left">Combination of a series of transforms which is applicable to images in Imagenet</td>
<td align="left">ResizeCropImagenet: <br> &ensp;&ensp; height: 224 <br> &ensp;&ensp; width: 224 <br> &ensp;&ensp; random_crop: False <br> &ensp;&ensp; resize_side: 256 <br> &ensp;&ensp; random_flip_left_right: False <br> &ensp;&ensp; mean_value: [123.68, 116.78, 103.94] <br> &ensp;&ensp; scale: 0.017</td>
</tr>
<tr>
<td align="left">QuantizedInput(dtype, scale)</td>
<td align="left"><strong>dtype</strong>(str): desired image dtype, support 'uint8', 'int8' <br> <strong>scale</strong>(float, default=None):scaling ratio of each point in image</td>
<td align="left">Convert the dtype of input to quantize it</td>
<td align="left">QuantizedInput: <br> &ensp;&ensp; dtype: 'uint8'</td>
</tr>
<tr>
<td align="left">LabelShift(label_shift)</td>
<td align="left"><strong>label_shift</strong>(int, default=0): number of label shift</td>
<td align="left">Convert label to label - label_shift</td>
<td align="left">LabelShift: <br> &ensp;&ensp; label_shift: 0</td>
</tr>
<tr>
<td align="left">BilinearImagenet(height, width, central_fraction, mean_value, scale)</td>
<td align="left"><strong>height</strong>(int): Height of the result <br> <strong>width</strong>(int):Width of the result <br> <strong>central_fraction</strong>(float, default=0.875):fraction of size to crop <br> <strong>mean_value</strong>(list, default=[0.0,0.0,0.0]):means for each channel <br> <strong>scale</strong>(float, default=1.0):std value</td>
<td align="left">Combination of a series of transforms which is applicable to images in Imagenet</td>
<td align="left">BilinearImagenet: <br> &ensp;&ensp; height: 224 <br> &ensp;&ensp; width: 224 <br> &ensp;&ensp; central_fraction: 0.875 <br> &ensp;&ensp; mean_value: [0.0,0.0,0.0] <br> &ensp;&ensp; scale: 1.0</td>
</tr>
<tr>
<td align="left">SquadV1(label_file, n_best_size, max_seq_length, max_query_length, max_answer_length, do_lower_case, doc_stride)</td>
<td align="left"><strong>label_file</strong> (str): path of label file <br> <strong>vocab_file</strong>(str): path of vocabulary file <br> <strong>n_best_size</strong> (int, default=20): The total number of n-best predictions to generate in the nbest_predictions.json output file <br> <strong>max_seq_length</strong> (int, default=384): The maximum total input sequence length after WordPiece tokenization. Sequences longer than this will be truncated, and sequences shorter, than this will be padded <br> <strong>max_query_length</strong> (int, default=64): The maximum number of tokens for the question. Questions longer than this will be truncated to this length <br> <strong>max_answer_length</strong> (int, default=30): The maximum length of an answer that can be generated. This is needed because the start and end predictions are not conditioned on one another <br> <strong>do_lower_case</strong> (bool, default=True): Whether to lower case the input text. Should be True for uncased models and False for cased models <br> <strong>doc_stride</strong> (int, default=128): When splitting up a long document into chunks, how much stride to take between chunks</td>
<td align="left">Postprocess the predictions of bert on SQuAD</td>
<td align="left">SquadV1 <br> &ensp;&ensp; label_file: /path/to/label_file <br> &ensp;&ensp; n_best_size: 20 <br> &ensp;&ensp; max_seq_length: 384 <br> &ensp;&ensp; max_query_length: 64 <br> &ensp;&ensp; max_answer_length: 30 <br> &ensp;&ensp; do_lower_case: True <br> &ensp;&ensp; doc_stride: True</td>
</tr>
</tbody>
</table></section>
<section id="pytorch">
<h3>Pytorch<a class="headerlink" href="#pytorch" title="Permalink to this headline">¶</a></h3>
<table border="1" class="docutils">
<thead>
<tr>
<th align="left">Transform</th>
<th align="left">Parameters</th>
<th align="left">Comments</th>
<th align="left">Usage(In yaml file)</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">Resize(size)</td>
<td align="left"><strong>size</strong> (list or int): Size of the result <br> interpolation(str, default='bilinear'):Desired interpolation type, support 'bilinear', 'nearest', 'bicubic'</td>
<td align="left">Resize the input image to the given size</td>
<td align="left">Resize: <br> &ensp;&ensp; size: 256 <br> &ensp;&ensp;  interpolation: bilinear</td>
</tr>
<tr>
<td align="left">CenterCrop(size)</td>
<td align="left"><strong>size</strong> (list or int): Size of the result</td>
<td align="left">Crops the given image at the center to the given size</td>
<td align="left">CenterCrop: <br> &ensp;&ensp; size: [10, 10] # or size: 10</td>
</tr>
<tr>
<td align="left">RandomResizedCrop(size, scale, ratio, interpolation)</td>
<td align="left"><strong>size</strong> (list or int): Size of the result <br> <strong>scale</strong> (tuple or list, default=(0.08, 1.0)):range of size of the origin size cropped <br> <strong>ratio</strong> (tuple or list, default=(3. / 4., 4. / 3.)): range of aspect ratio of the origin aspect ratio cropped <br> <strong>interpolation</strong> (str, default='bilinear'):Desired interpolation type, support 'bilinear', 'nearest', 'bicubic'</td>
<td align="left">Crop the given image to random size and aspect ratio</td>
<td align="left">RandomResizedCrop: <br> &ensp;&ensp; size: [10, 10] # or size: 10 <br> &ensp;&ensp; scale: [0.08, 1.0] <br> &ensp;&ensp; ratio: [3. / 4., 4. / 3.] <br> &ensp;&ensp; interpolation: bilinear</td>
</tr>
<tr>
<td align="left">Normalize(mean, std)</td>
<td align="left"><strong>mean</strong> (list, default=[0.0]):means for each channel, if len(mean)=1, mean will be broadcasted to each channel, otherwise its length should be same with the length of image shape <br> <strong>std</strong> (list, default=[1.0]):stds for each channel, if len(std)=1, std will be broadcasted to each channel, otherwise its length should be same with the length of image shape</td>
<td align="left">Normalize a image with mean and standard deviation</td>
<td align="left">Normalize: <br> &ensp;&ensp; mean: [0.0, 0.0, 0.0] <br> &ensp;&ensp; std: [1.0, 1.0, 1.0]</td>
</tr>
<tr>
<td align="left">RandomCrop(size)</td>
<td align="left"><strong>size</strong> (list or int): Size of the result</td>
<td align="left">Crop the image at a random location to the given size</td>
<td align="left">RandomCrop: <br> &ensp;&ensp; size: [10, 10] # size: 10</td>
</tr>
<tr>
<td align="left">Compose(transform_list)</td>
<td align="left"><strong>transform_list</strong> (list of Transform objects):  list of transforms to compose</td>
<td align="left">Composes several transforms together</td>
<td align="left">If user uses yaml file to configure transforms, LPOT will automatic call Compose to group other transforms. <br> <strong>In user code:</strong> <br> from lpot.experimental.data  import TRANSFORMS <br> preprocess = TRANSFORMS(framework, 'preprocess') <br> resize = preprocess["Resize"] (*<em>args) <br> normalize = preprocess["Normalize"] (*</em>args) <br> compose = preprocess["Compose"] ([resize, normalize]) <br> sample = compose(sample) <br> # sample: image, label</td>
</tr>
<tr>
<td align="left">RandomHorizontalFlip()</td>
<td align="left">None</td>
<td align="left">Horizontally flip the given image randomly</td>
<td align="left">RandomHorizontalFlip: {}</td>
</tr>
<tr>
<td align="left">RandomVerticalFlip()</td>
<td align="left">None</td>
<td align="left">Vertically flip the given image randomly</td>
<td align="left">RandomVerticalFlip: {}</td>
</tr>
<tr>
<td align="left">Transpose(perm)</td>
<td align="left"><strong>perm</strong> (list): A permutation of the dimensions of input image</td>
<td align="left">Transpose image according perm</td>
<td align="left">Transpose: <br> &ensp;&ensp; perm: [1, 2, 0]</td>
</tr>
<tr>
<td align="left">CropToBoundingBox(offset_height, offset_width, target_height, target_width)</td>
<td align="left"><strong>offset_height</strong> (int): Vertical coordinate of the top-left corner of the result in the input <br> <strong>offset_width</strong> (int): Horizontal coordinate of the top-left corner of the result in the input <br> <strong>target_height</strong> (int): Height of the result <br> <strong>target_width</strong> (int): Width of the result</td>
<td align="left">Crops an image to a specified bounding box</td>
<td align="left">CropToBoundingBox: <br> &ensp;&ensp; offset_height: 10 <br> &ensp;&ensp; offset_width: 10 <br> &ensp;&ensp; target_height: 224 <br> &ensp;&ensp; 224</td>
</tr>
<tr>
<td align="left">ToTensor()</td>
<td align="left">None</td>
<td align="left">Convert a PIL Image or numpy.ndarray to tensor</td>
<td align="left">ToTensor: {}</td>
</tr>
<tr>
<td align="left">ToPILImage()</td>
<td align="left">None</td>
<td align="left">Convert a tensor or an ndarray to PIL Image</td>
<td align="left">ToPILImage: {}</td>
</tr>
<tr>
<td align="left">Pad(padding, fill, padding_mode)</td>
<td align="left"><strong>padding</strong> (int or tuple or list): Padding on each border <br> <strong>fill</strong> (int or str or tuple): Pixel fill value for constant fill. Default is 0 <br> <strong>padding_mode</strong> (str): Type of padding. Should be: constant, edge, reflect or symmetric. Default is constant</td>
<td align="left">Pad the given image on all sides with the given “pad” value</td>
<td align="left">Pad: <br> &ensp;&ensp; padding: 0 <br> &ensp;&ensp; fill: 0 <br> &ensp;&ensp; padding_mode: constant</td>
</tr>
<tr>
<td align="left">ColorJitter(brightness, contrast, saturation, hue)</td>
<td align="left"><strong>brightness</strong> (float or tuple of python:float (min, max)): How much to jitter brightness. Default is 0 <br> <strong>contrast</strong> (float or tuple of python:float (min, max)): How much to jitter contrast. Default is 0 <br> <strong>saturation</strong> (float or tuple of python:float (min, max)): How much to jitter saturation. Default is 0 <br> <strong>hue</strong> (float or tuple of python:float (min, max)): How much to jitter hue. Default is 0</td>
<td align="left">Randomly change the brightness, contrast, saturation and hue of an image</td>
<td align="left">ColorJitter: <br> &ensp;&ensp; brightness: 0 <br> &ensp;&ensp; contrast: 0 <br> &ensp;&ensp; saturation: 0 <br> &ensp;&ensp; hue: 0</td>
</tr>
<tr>
<td align="left">ToArray()</td>
<td align="left">None</td>
<td align="left">Convert PIL Image to numpy array</td>
<td align="left">ToArray: {}</td>
</tr>
<tr>
<td align="left">CropResize(x, y, width, height, size, interpolation)</td>
<td align="left"><strong>x</strong> (int):Left boundary of the cropping area <br> <strong>y</strong> (int):Top boundary of the cropping area <br> <strong>width</strong> (int):Width of the cropping area <br> <strong>height</strong> (int):Height of the cropping area <br> <strong>size</strong> (list or int): resize to new size after cropping <br> <strong>interpolation</strong> (str, default='bilinear'):Desired interpolation type, support 'bilinear', 'nearest', 'bicubic'</td>
<td align="left">Crop the input image with given location and resize it</td>
<td align="left">CropResize: <br> &ensp;&ensp; x: 0 <br> &ensp;&ensp; y: 5 <br> &ensp;&ensp; width: 224 <br> &ensp;&ensp; height: 224 <br> &ensp;&ensp; size: [100, 100] # or size: 100 <br> &ensp;&ensp; interpolation: bilinear</td>
</tr>
<tr>
<td align="left">Cast(dtype)</td>
<td align="left"><strong>dtype</strong> (str, default ='float32') :The target data type</td>
<td align="left">Convert image to given dtype</td>
<td align="left">Cast: <br> &ensp;&ensp; dtype: float32</td>
</tr>
<tr>
<td align="left">AlignImageChannel(dim)</td>
<td align="left"><strong>dim</strong> (int): The channel number of result image</td>
<td align="left">Align image channel, now just support [H,W,4]-&gt;[H,W,3] and [H,W,3]-&gt;[H,W], input image must be PIL Image</td>
<td align="left">AlignImageChannel: <br> &ensp;&ensp; dim: 3</td>
</tr>
<tr>
<td align="left">ResizeWithRatio(min_dim, max_dim, padding)</td>
<td align="left"><strong>min_dim</strong> (int, default=800): Resizes the image such that its smaller dimension == min_dim <br> <strong>max_dim</strong> (int, default=1365): Ensures that the image longest side does not exceed this value <br> <strong>padding</strong> (bool, default=False): If true, pads image with zeros so its size is max_dim x max_dim</td>
<td align="left">Resize image with aspect ratio and pad it to max shape(optional). If the image is padded, the label will be processed at the same time. The input image should be np.array.</td>
<td align="left">ResizeWithRatio: <br> &ensp;&ensp; min_dim: 800 <br> &ensp;&ensp; max_dim: 1365 <br> &ensp;&ensp; padding: True</td>
</tr>
</tbody>
</table></section>
<section id="mxnet">
<h3>MXNet<a class="headerlink" href="#mxnet" title="Permalink to this headline">¶</a></h3>
<table border="1" class="docutils">
<thead>
<tr>
<th align="left">Transform</th>
<th align="left">Parameters</th>
<th align="left">Comments</th>
<th align="left">Usage(In yaml file)</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">Resize(size, interpolation)</td>
<td align="left"><strong>size</strong> (list or int): Size of the result <br> <strong>interpolation</strong> (str, default='bilinear'):Desired interpolation type, support 'bilinear', 'nearest', 'bicubic'</td>
<td align="left">Resize the input image to the given size</td>
<td align="left">Resize: <br> &ensp;&ensp; size: 256 <br> &ensp;&ensp;  interpolation: bilinear</td>
</tr>
<tr>
<td align="left">CenterCrop(size)</td>
<td align="left"><strong>size</strong> (list or int): Size of the result</td>
<td align="left">Crops the given image at the center to the given size</td>
<td align="left">CenterCrop: <br> &ensp;&ensp; size: [10, 10] # or size: 10</td>
</tr>
<tr>
<td align="left">RandomResizedCrop(size, scale, ratio, interpolation)</td>
<td align="left"><strong>size</strong> (list or int): Size of the result <br> <strong>scale</strong> (tuple or list, default=(0.08, 1.0)):range of size of the origin size cropped <br> <strong>ratio</strong> (tuple or list, default=(3. / 4., 4. / 3.)): range of aspect ratio of the origin aspect ratio cropped <br> <strong>interpolation</strong> (str, default='bilinear'):Desired interpolation type, support 'bilinear', 'nearest', 'bicubic'</td>
<td align="left">Crop the given image to random size and aspect ratio</td>
<td align="left">RandomResizedCrop: <br> &ensp;&ensp; size: [10, 10] # or size: 10 <br> &ensp;&ensp; scale: [0.08, 1.0] <br> &ensp;&ensp; ratio: [3. / 4., 4. / 3.] <br> &ensp;&ensp; interpolation: bilinear</td>
</tr>
<tr>
<td align="left">Normalize(mean, std)</td>
<td align="left"><strong>mean</strong> (list, default=[0.0]):means for each channel, if len(mean)=1, mean will be broadcasted to each channel, otherwise its length should be same with the length of image shape <br> <strong>std</strong> (list, default=[1.0]):stds for each channel, if len(std)=1, std will be broadcasted to each channel, otherwise its length should be same with the length of image shape</td>
<td align="left">Normalize a image with mean and standard deviation</td>
<td align="left">Normalize: <br> &ensp;&ensp; mean: [0.0, 0.0, 0.0] <br> &ensp;&ensp; std: [1.0, 1.0, 1.0]</td>
</tr>
<tr>
<td align="left">RandomCrop(size)</td>
<td align="left"><strong>size</strong> (list or int): Size of the result</td>
<td align="left">Crop the image at a random location to the given size</td>
<td align="left">RandomCrop: <br> &ensp;&ensp; size: [10, 10] # size: 10</td>
</tr>
<tr>
<td align="left">Compose(transform_list)</td>
<td align="left"><strong>transform_list</strong> (list of Transform objects):  list of transforms to compose</td>
<td align="left">Composes several transforms together</td>
<td align="left">If user uses yaml file to configure transforms, LPOT will automatic call Compose to group other transforms. <br> <strong>In user code:</strong> <br> from lpot.experimental.data  import TRANSFORMS <br> preprocess = TRANSFORMS(framework, 'preprocess') <br> resize = preprocess["Resize"] (*<em>args) <br> normalize = preprocess["Normalize"] (*</em>args) <br> compose = preprocess["Compose"] ([resize, normalize]) <br> sample = compose(sample) <br> # sample: image, label</td>
</tr>
<tr>
<td align="left">CropResize(x, y, width, height, size, interpolation)</td>
<td align="left"><strong>x</strong> (int):Left boundary of the cropping area <br> <strong>y</strong> (int):Top boundary of the cropping area <br> <strong>width</strong> (int):Width of the cropping area <br> <strong>height</strong> (int):Height of the cropping area <br> <strong>size</strong> (list or int): resize to new size after cropping <br> <strong>interpolation</strong> (str, default='bilinear'):Desired interpolation type, support 'bilinear', 'nearest', 'bicubic'</td>
<td align="left">Crop the input image with given location and resize it</td>
<td align="left">CropResize: <br> &ensp;&ensp; x: 0 <br> &ensp;&ensp; y: 5 <br> &ensp;&ensp; width: 224 <br> &ensp;&ensp; height: 224 <br> &ensp;&ensp; size: [100, 100] # or size: 100 <br> &ensp;&ensp; interpolation: bilinear</td>
</tr>
<tr>
<td align="left">RandomHorizontalFlip()</td>
<td align="left">None</td>
<td align="left">Horizontally flip the given image randomly</td>
<td align="left">RandomHorizontalFlip: {}</td>
</tr>
<tr>
<td align="left">RandomVerticalFlip()</td>
<td align="left">None</td>
<td align="left">Vertically flip the given image randomly</td>
<td align="left">RandomVerticalFlip: {}</td>
</tr>
<tr>
<td align="left">CropToBoundingBox(offset_height, offset_width, target_height, target_width)</td>
<td align="left"><strong>offset_height</strong> (int): Vertical coordinate of the top-left corner of the result in the input <br> <strong>offset_width</strong> (int): Horizontal coordinate of the top-left corner of the result in the input <br> <strong>target_height</strong> (int): Height of the result <br> <strong>target_width</strong> (int): Width of the result</td>
<td align="left">Crops an image to a specified bounding box</td>
<td align="left">CropToBoundingBox: <br> &ensp;&ensp; offset_height: 10 <br> &ensp;&ensp; offset_width: 10 <br> &ensp;&ensp; target_height: 224 <br> &ensp;&ensp; 224</td>
</tr>
<tr>
<td align="left">ToArray()</td>
<td align="left">None</td>
<td align="left">Convert NDArray to numpy array</td>
<td align="left">ToArray: {}</td>
</tr>
<tr>
<td align="left">ToTensor()</td>
<td align="left">None</td>
<td align="left">Converts an image NDArray or batch of image NDArray to a tensor NDArray</td>
<td align="left">ToTensor: {}</td>
</tr>
<tr>
<td align="left">Cast(dtype)</td>
<td align="left"><strong>dtype</strong> (str, default ='float32') :The target data type</td>
<td align="left">Convert image to given dtype</td>
<td align="left">Cast: <br> &ensp;&ensp; dtype: float32</td>
</tr>
<tr>
<td align="left">Transpose(perm)</td>
<td align="left"><strong>perm</strong> (list): A permutation of the dimensions of input image</td>
<td align="left">Transpose image according perm</td>
<td align="left">Transpose: <br> &ensp;&ensp; perm: [1, 2, 0]</td>
</tr>
<tr>
<td align="left">AlignImageChannel(dim)</td>
<td align="left"><strong>dim</strong> (int): The channel number of result image</td>
<td align="left">Align image channel, now just support [H,W]-&gt;[H,W,dim], [H,W,4]-&gt;[H,W,3] and [H,W,3]-&gt;[H,W]</td>
<td align="left">AlignImageChannel: <br> &ensp;&ensp; dim: 3</td>
</tr>
<tr>
<td align="left">ToNDArray()</td>
<td align="left">None</td>
<td align="left">Convert np.array to NDArray</td>
<td align="left">ToNDArray: {}</td>
</tr>
<tr>
<td align="left">ResizeWithRatio(min_dim, max_dim, padding)</td>
<td align="left"><strong>min_dim</strong> (int, default=800): Resizes the image such that its smaller dimension == min_dim <br> <strong>max_dim</strong> (int, default=1365): Ensures that the image longest side does not exceed this value <br> <strong>padding</strong> (bool, default=False): If true, pads image with zeros so its size is max_dim x max_dim</td>
<td align="left">Resize image with aspect ratio and pad it to max shape(optional). If the image is padded, the label will be processed at the same time. The input image should be np.array.</td>
<td align="left">ResizeWithRatio: <br> &ensp;&ensp; min_dim: 800 <br> &ensp;&ensp; max_dim: 1365 <br> &ensp;&ensp; padding: True</td>
</tr>
</tbody>
</table></section>
<section id="onnxrt">
<h3>ONNXRT<a class="headerlink" href="#onnxrt" title="Permalink to this headline">¶</a></h3>
<table border="1" class="docutils">
<thead>
<tr>
<th align="left">Type</th>
<th align="left">Parameters</th>
<th align="left">Comments</th>
<th align="left">Usage(In yaml file)</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">Resize(size, interpolation)</td>
<td align="left"><strong>size</strong> (list or int): Size of the result <br> <strong>interpolation</strong> (str, default='bilinear'):Desired interpolation type, support 'bilinear', 'nearest', 'bicubic'</td>
<td align="left">Resize the input image to the given size</td>
<td align="left">Resize: <br> &ensp;&ensp; size: 256 <br> &ensp;&ensp;  interpolation: bilinear</td>
</tr>
<tr>
<td align="left">CenterCrop(size)</td>
<td align="left"><strong>size</strong> (list or int): Size of the result</td>
<td align="left">Crops the given image at the center to the given size</td>
<td align="left">CenterCrop: <br> &ensp;&ensp; size: [10, 10] # or size: 10</td>
</tr>
<tr>
<td align="left">RandomResizedCrop(size, scale, ratio, interpolation)</td>
<td align="left"><strong>size</strong> (list or int): Size of the result <br> <strong>scale</strong> (tuple or list, default=(0.08, 1.0)):range of size of the origin size cropped <br> <strong>ratio</strong> (tuple or list, default=(3. / 4., 4. / 3.)): range of aspect ratio of the origin aspect ratio cropped <br> <strong>interpolation</strong> (str, default='bilinear'):Desired interpolation type, support 'bilinear', 'nearest'</td>
<td align="left">Crop the given image to random size and aspect ratio</td>
<td align="left">RandomResizedCrop: <br> &ensp;&ensp; size: [10, 10] # or size: 10 <br> &ensp;&ensp; scale: [0.08, 1.0] <br> &ensp;&ensp; ratio: [3. / 4., 4. / 3.] <br> &ensp;&ensp; interpolation: bilinear</td>
</tr>
<tr>
<td align="left">Normalize(mean, std)</td>
<td align="left"><strong>mean</strong> (list, default=[0.0]):means for each channel, if len(mean)=1, mean will be broadcasted to each channel, otherwise its length should be same with the length of image shape <br> <strong>std</strong> (list, default=[1.0]):stds for each channel, if len(std)=1, std will be broadcasted to each channel, otherwise its length should be same with the length of image shape</td>
<td align="left">Normalize a image with mean and standard deviation</td>
<td align="left">Normalize: <br> &ensp;&ensp; mean: [0.0, 0.0, 0.0] <br> &ensp;&ensp; std: [1.0, 1.0, 1.0]</td>
</tr>
<tr>
<td align="left">RandomCrop(size)</td>
<td align="left"><strong>size</strong> (list or int): Size of the result</td>
<td align="left">Crop the image at a random location to the given size</td>
<td align="left">RandomCrop: <br> &ensp;&ensp; size: [10, 10] # size: 10</td>
</tr>
<tr>
<td align="left">Compose(transform_list)</td>
<td align="left"><strong>transform_list</strong> (list of Transform objects):  list of transforms to compose</td>
<td align="left">Composes several transforms together</td>
<td align="left">If user uses yaml file to configure transforms, LPOT will automatic call Compose to group other transforms. <br> <strong>In user code:</strong> <br> from lpot.experimental.data  import TRANSFORMS <br> preprocess = TRANSFORMS(framework, 'preprocess') <br> resize = preprocess["Resize"] (*<em>args) <br> normalize = preprocess["Normalize"] (*</em>args) <br> compose = preprocess["Compose"] ([resize, normalize]) <br> sample = compose(sample) <br> # sample: image, label</td>
</tr>
<tr>
<td align="left">CropResize(x, y, width, height, size, interpolation)</td>
<td align="left"><strong>x</strong> (int):Left boundary of the cropping area <br> <strong>y</strong> (int):Top boundary of the cropping area <br> <strong>width</strong> (int):Width of the cropping area <br> <strong>height</strong> (int):Height of the cropping area <br> <strong>size</strong> (list or int): resize to new size after cropping <br> <strong>interpolation</strong> (str, default='bilinear'):Desired interpolation type, support 'bilinear', 'nearest'</td>
<td align="left">Crop the input image with given location and resize it</td>
<td align="left">CropResize: <br> &ensp;&ensp; x: 0 <br> &ensp;&ensp; y: 5 <br> &ensp;&ensp; width: 224 <br> &ensp;&ensp; height: 224 <br> &ensp;&ensp; size: [100, 100] # or size: 100 <br> &ensp;&ensp; interpolation: bilinear</td>
</tr>
<tr>
<td align="left">RandomHorizontalFlip()</td>
<td align="left">None</td>
<td align="left">Horizontally flip the given image randomly</td>
<td align="left">RandomHorizontalFlip: {}</td>
</tr>
<tr>
<td align="left">RandomVerticalFlip()</td>
<td align="left">None</td>
<td align="left">Vertically flip the given image randomly</td>
<td align="left">RandomVerticalFlip: {}</td>
</tr>
<tr>
<td align="left">CropToBoundingBox(offset_height, offset_width, target_height, target_width)</td>
<td align="left"><strong>offset_height</strong> (int): Vertical coordinate of the top-left corner of the result in the input <br> <strong>offset_width</strong> (int): Horizontal coordinate of the top-left corner of the result in the input <br> <strong>target_height</strong> (int): Height of the result <br> <strong>target_width</strong> (int): Width of the result</td>
<td align="left">Crops an image to a specified bounding box</td>
<td align="left">CropToBoundingBox: <br> &ensp;&ensp; offset_height: 10 <br> &ensp;&ensp; offset_width: 10 <br> &ensp;&ensp; target_height: 224 <br> &ensp;&ensp; 224</td>
</tr>
<tr>
<td align="left">ToArray()</td>
<td align="left">None</td>
<td align="left">Convert PIL Image to numpy array</td>
<td align="left">ToArray: {}</td>
</tr>
<tr>
<td align="left">Rescale()</td>
<td align="left">None</td>
<td align="left">Scale the values of image to [0,1]</td>
<td align="left">Rescale: {}</td>
</tr>
<tr>
<td align="left">AlignImageChannel(dim)</td>
<td align="left"><strong>dim</strong> (int): The channel number of result image</td>
<td align="left">Align image channel, now just support [H,W]-&gt;[H,W,dim], [H,W,4]-&gt;[H,W,3] and [H,W,3]-&gt;[H,W]</td>
<td align="left">AlignImageChannel: <br> &ensp;&ensp; dim: 3</td>
</tr>
<tr>
<td align="left">ResizeCropImagenet(height, width, random_crop, resize_side, random_flip_left_right, mean_value, scale)</td>
<td align="left"><strong>height</strong> (int): Height of the result <br> <strong>width</strong> (int): Width of the result <br> <strong>random_crop</strong> (bool, default=False): whether to random crop <br> <strong>resize_side</strong> (int, default=256):desired shape after resize operation <br> <strong>random_flip_left_right</strong> (bool, default=False): whether to random flip left and right <br> <strong>mean_value</strong> (list, default=[0.0,0.0,0.0]):mean for each channel <br> <strong>scale</strong> (float, default=1.0):std value</td>
<td align="left">Combination of a series of transforms which is applicable to images in Imagenet</td>
<td align="left">ResizeCropImagenet: <br> &ensp;&ensp; height: 224 <br> &ensp;&ensp; width: 224 <br> &ensp;&ensp; random_crop: False <br> &ensp;&ensp; resize_side: 256 <br> &ensp;&ensp; random_flip_left_right: False <br> &ensp;&ensp; mean_value: [123.68, 116.78, 103.94] <br> &ensp;&ensp; scale: 0.017</td>
</tr>
<tr>
<td align="left">Cast(dtype)</td>
<td align="left"><strong>dtype</strong> (str, default ='float32') :The target data type</td>
<td align="left">Convert image to given dtype</td>
<td align="left">Cast: <br> &ensp;&ensp; dtype: float32</td>
</tr>
<tr>
<td align="left">ResizeWithRatio(min_dim, max_dim, padding)</td>
<td align="left"><strong>min_dim</strong> (int, default=800): Resizes the image such that its smaller dimension == min_dim <br> <strong>max_dim</strong> (int, default=1365): Ensures that the image longest side does not exceed this value <br> <strong>padding</strong> (bool, default=False): If true, pads image with zeros so its size is max_dim x max_dim</td>
<td align="left">Resize image with aspect ratio and pad it to max shape(optional). If the image is padded, the label will be processed at the same time. The input image should be np.array.</td>
<td align="left">ResizeWithRatio: <br> &ensp;&ensp; min_dim: 800 <br> &ensp;&ensp; max_dim: 1365 <br> &ensp;&ensp; padding: True</td>
</tr>
</tbody>
</table></section>
</section>
</section>


              </div>
              
              
              <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="../system_requirements.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">System Requirements</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="dataset.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Dataset</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
              
          </main>
          

      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>
<footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2021, Intel® Low Precision Optimization Tool.<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.3.0.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>